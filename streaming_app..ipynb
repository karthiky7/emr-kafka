{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%spark\n",
        "import org.apache.spark.sql.SparkSession\n",
        "import org.apache.spark.sql.functions._\n",
        "import org.apache.spark.sql.streaming._\n",
        "import org.apache.spark.sql.types._\n",
        "val spark = SparkSession.builder.appName(\"streaming Application\").config(\"spark.sql.catalogImplementation\",\"in-memory\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%spark\n",
        "import org.apache.spark.sql.*;\n",
        "import org.apache.spark.sql.streaming.StreamingQuery;\n",
        "import org.apache.spark.sql.streaming.Trigger;\n",
        "import static org.apache.spark.sql.functions.col;\n",
        "import static org.apache.spark.sql.avro.functions.*;\n",
        "\n",
        "val jsonFormatSchema = new String(Files.readAllBytes(Paths.get(\"./src/main/resources/user.avsc\")))\n",
        "\n",
        "\n",
        "SparkSession spark = SparkSession\n",
        "  .builder()\n",
        "  .appName(\"Streaming Application\")\n",
        "  .getOrCreate();\n",
        "\n",
        "\n",
        "Dataset<Row> df = spark.readStream.format(\"kafka\").option(\"kafka.bootstrap.servers\", \"b-3.demo-cluster-1.25yk5g.c8.kafka.eu-west-1.amazonaws.com:9092,b-1.demo-cluster-1.25yk5g.c8.kafka.eu-west-1.amazonaws.com:9092,b-2.demo-cluster-1.25yk5g.c8.kafka.eu-west-1.amazonaws.com:9092\").option(\"subscribe\", \"MSKTutorialTopic\").option(\"startingOffsets\", \"earliest\").load()\n",
        "Dataset<Row> output = df.select(from_avro(col(\"value\"), jsonFormatSchema).as(\"record\")).select(\"record.*\")\n",
        "StreamingQuery query = output.writeStream\n",
        "  .format(\"csv\")\n",
        "  .option(\"checkpointLocation\", \"/tmp/test\")\n",
        "  .option(\"path\", \"/output/\")\n",
        "  .trigger(Trigger.ProcessingTime(\"1 seconds\"))\n",
        "  .start()\n",
        "query.awaitTermination()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    },
    "name": "streaming_app"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
